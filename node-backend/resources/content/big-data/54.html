<head>
    <style>
        body, td {
            font-family: Segoe UI;
            font-size: 10pt;
        }
    </style>
</head>

<div><div>Normally when you have 2 tier web application, it is fairly easy and there is no apparent need to over complicate things. A good example is just a web application connecting to the database. <br/></div><div><br/></div><div>It can illustrated as just:</div><div><span
        style="">Source System --&gt; Target System</span></div><div><br/></div><div><h4><font style="font-size: 24px;">What is it trying to solve?</font></h4></div><div>However if there are more Tiers/Systems involves, say your sources comes from different sources, like from websites/APIs/User Transactions. Your Target are multiple systems as well like your Database/Audit/Email API/Audit. Cross dependencies has come to similar to like this:<img
        src="/images/54_files/Screen Shot 2018-02-21 at 7.42.33 pm.png" type="image/png"
        data-filename="Screen Shot 2018-02-21 at 7.42.33 pm.png" className="img-responsive" width="100%"/></div><div>It can get complicated real quick!</div><div><br/></div><div><h4><font
        style="font-size: 18px;">Kafka tries to act as the middle tier as some sort of gateway for all the system, like this:</font><img
        src="/images/54_files/Screen Shot 2018-02-21 at 7.43.17 pm.png" type="image/png"
        data-filename="Screen Shot 2018-02-21 at 7.43.17 pm.png" style="font-weight: bold;" width="100%"/></h4></div><div><h4><br/></h4></div><div><h4>Kafka in a quick summary is a Persistent Messaging Queue that gives your architecture room to scale.</h4></div><div><br/></div><div><h4><font
        style="font-size: 24px;">Kafka Integration:</font></h4></div><div>Integration can easily broken down to two:</div><div><ul><li>Producer - these are what are in charge of pumping in data to Kafka</li><li>Consumer - these are what are in charge of reading data from Kafka </li></ul></div><div>Each integration with Kafka interacts with either Producer/Consumer as below:</div><div><img
        src="/images/54_files/Screen Shot 2018-02-21 at 7.53.48 pm.png" type="image/png"
        data-filename="Screen Shot 2018-02-21 at 7.53.48 pm.png" width="100%"/></div><div><i>Above diagrams are basic architecture, (different topic on a zookeeper, but in summary zookeeper is needed as it handles your Kafka)</i></div><div><i><br/></i></div><div><h4><font
        style="font-size: 24px;">Key Concepts</font></h4></div><div><ul><li><h4><font
        style="font-size: 18px;">Topics</font></h4><span style="font-size: 13px;"> - Similar to how databases have Tables, Kafka/Messaging Queues have Topics, these are where the datas are stored (in a partition of a topic)</span><br/></li><li><h4><font
        style="font-size: 18px;">Partitions</font></h4><span style="font-size: 13px;"> - Topics are broken down into partitions, so a topic can have multiple partitions</span></li><ul><li><span
        style="font-size: 13px;">Partitions are ordered</span></li></ul><li><span style="font-size: 13px;">Offsets - Offset is the identifier, that increments every time you enter a data in a topic/partition</span></li></ul><span
        style="font-size: 13px;">Below is how a Topic would like inside if it had 3 Partitions:</span></div><div><img
        src="/images/54_files/Screen Shot 2018-02-21 at 8.01.36 pm.png" type="image/png"
        data-filename="Screen Shot 2018-02-21 at 8.01.36 pm.png" width="100%"/></div><div><ul><li>Numbers inside each partitions are the offset, for example in Partition 1, the current offset is 8, so there were 9 entries inside the partition (we start counting at 0)</li><li>Data is stored randomly (unless a key is provided) in random partition</li><ul><li>NOTE: If you want specific data to go to specific partitions, message keys are used, but the problem here is that one partition can have a lot of data while others don’t. There can be an imbalance</li></ul></ul><div><br/></div><div>By default, you can have unlimited topics/partitions. And data is stored at 2 weeks. Kafka is meant to be used as a middleware not as data storage.</div><div><br/></div><div><h4><font
        style="font-size: 18px;">Brokers</font></h4></div><div>In Kafka, servers are called Brokers. (Similar to Database perhaps)</div></div><div>In database a good comparison would probably be:</div><div><br/></div><div><ul><li>Brokers = Database Schema<br/></li><li>Topics = Tables</li></ul><div>Brokers are usually identified with an ID. A visual representation would be   below, here we have 3 Brokers, with 2 topics and 3 partitions</div></div><div><br/></div><div><br/></div><div><img
        src="/images/54_files/Screen Shot 2018-02-21 at 8.09.09 pm.png" type="image/png"
        data-filename="Screen Shot 2018-02-21 at 8.09.09 pm.png" width="100%"/></div><div><br/></div><div><font
        style="font-size: 18px;"><h4>Replication Factor</h4></font></div><div><font size="1"><b
        style="font-size: 14px;"></h4><span style="font-size: 14px;">In Kafka, we can specify replication factors, to ensure more resiliency, topics are replicated across brokers, as per below<br/></span></font></div><div><img
        src="/images/54_files/Screen Shot 2018-02-21 at 8.11.04 pm.png" type="image/png"
        data-filename="Screen Shot 2018-02-21 at 8.11.04 pm.png" width="100%"/></div><div><br/></div><div><h4><font
        style="font-size: 18px;">Producers</font></h4></div><div><font><span
        style="font-size: 18px;"><h4>   </h4></span><font style="font-size: 14px;">There are different levels of acknowledgements in Producers. Basically when you want to send data to a producer, do you want a broker to acknowledge that he has received the data or not.</font><br/></font></div><div><ul><li>Acks=0 - Producer won’t wait for acknowledgement, so your code just sends in a message and assumes it has been received </li><ul><li>Possible loss of data</li></ul><li>Acks=1 - Waits for the leader to acknowledge the data, due to the fact that we have replication as mentioned above there are leaders set (This is set by zookeeper, and is in a seperate topic on its own)</li><ul><li>Limited data loss</li></ul><li>Acks=2 - waits for all brokers to acknowledge the data</li></ul><div>So depending on how sensitive the data is, or what the level of performance you want, you are going to tweak this to suit your needs.</div></div><div><br/></div><div><font
        size="1"><b style="font-size: 18px;">Consumers</h4></font></div><div><b style="font-size: 14px;"></h4>it is important to note that consumer consumes messages in parallel for all the partitions, as per below, <br/></div><div><font
        size="1"><b style="font-size: 18px;"><img src="/images/54_files/Screen Shot 2018-02-21 at 8.20.29 pm.png"
                                                  type="image/png"
                                                  data-filename="Screen Shot 2018-02-21 at 8.20.29 pm.png"
                                                  style="font-weight: bold; font-size: 18px;" width="100%"/><br/></h4></font></div><div><b
        style="font-size: 18px;">Consumer Groups</h4><br/></div><div><b style="font-size: 14px;"></h4>Problem with above is if you have a lot of partitions, as mentioned above you have unlimited number of partitions, and so it will be burdensome to one consumer. <br/></div><div><br/></div><div>So to encourage parallelism consumer groups joins together consumers and reads from one specific partition only.</div><div><br/></div><div><img
        src="/images/54_files/Screen Shot 2018-02-21 at 8.23.03 pm.png" type="image/png"
        data-filename="Screen Shot 2018-02-21 at 8.23.03 pm.png" width="100%"/></div><div><br/></div><div>In the example above, we have 1 topic with 3 partitions</div><div><ul><li>In Consumer Group 0 (2 Consumers) = 2 partitions will be read by consumer 1, and 1 partition in consumer 2<br/></li><li>In Consumer Group 1 (3 Consumers) = each partition is assigned to each Consumer</li><li>In Consumer Group 2 (1 Consumer) = all partitions are read by Consumer 1</li></ul></div><div><br/></div><div>We’ve covered the basic concepts of Kafka, it is good to get your hands dirty with Kafka, and try out how interact with the topics. Once you have Kafka running there are built-in scripts on how you can create topic etc etc. I will probably covered this in a seperate topic as well.</div>
</div>
